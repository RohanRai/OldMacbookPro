{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Imports\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n"
     ]
    }
   ],
   "source": [
    "# Grab data from current directory\n",
    "\n",
    "raw_data = list()\n",
    "with open('diabetes.csv') as file:\n",
    "    reader = csv.reader(file)\n",
    "    \n",
    "    for row in reader:\n",
    "        if len(row) > 0:\n",
    "            try:\n",
    "                raw_data.append(np.array(row, dtype='f'))\n",
    "            except:\n",
    "                print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Split data into train and test datasets\n",
    "\n",
    "## TODO: Randomly choose 540 points for training data rather than first 540\n",
    "\n",
    "X_train = np.array(raw_data[:540])\n",
    "Y_train = X_train[:,-1]\n",
    "X_train = X_train[:, :-1]\n",
    "\n",
    "\n",
    "X_test = np.array(raw_data[540:])\n",
    "Y_test = X_test[:,-1]\n",
    "X_test = X_test[:, :-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 8) (350, 8)\n"
     ]
    }
   ],
   "source": [
    "#  Split train data set into positive and negatie cases\n",
    "\n",
    "X_train_1 = list()\n",
    "X_train_0 = list()\n",
    "for i, row in enumerate(X_train):\n",
    "    if Y_train[i] == 1:\n",
    "        X_train_1.append(row)\n",
    "    else:\n",
    "        X_train_0.append(row)\n",
    "        \n",
    "X_train_1 = np.array(X_train_1, dtype='f')\n",
    "X_train_0 = np.array(X_train_0, dtype='f')\n",
    "\n",
    "print(X_train_1.shape, X_train_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Find means and std of each column\n",
    "\n",
    "columnMeans_0 = list()\n",
    "columnMeans_1 = list()\n",
    "columnSTD_0 = list()\n",
    "columnSTD_1 = list()\n",
    "for i in range(8):\n",
    "    columnMeans_0.append(np.mean(X_train_0[:,i]))\n",
    "    columnMeans_1.append(np.mean(X_train_1[:,i]))\n",
    "    columnSTD_0.append(np.std(X_train_0[:,i]))\n",
    "    columnSTD_1.append(np.std(X_train_1[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.26, 109.777145, 67.90857, 19.53143, 67.69143, 29.939716, 0.44142282, 31.385714]\n",
      "[4.8210526, 139.6421, 69.68421, 21.847368, 100.82632, 35.26, 0.5659263, 36.33684]\n",
      "[2.974818, 27.318577, 17.87505, 14.816126, 102.21673, 7.986814, 0.30297697, 11.95168]\n",
      "[3.7556386, 32.482357, 22.422388, 17.17841, 138.13402, 7.358288, 0.38852227, 10.630256]\n"
     ]
    }
   ],
   "source": [
    "# Print means and stds of each feature for positive and negative cases\n",
    "\n",
    "print(columnMeans_0)\n",
    "print(columnMeans_1)\n",
    "print(columnSTD_0)\n",
    "print(columnSTD_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normpdf(x, mu, sigma):\n",
    "    coeff = 1/(sigma*np.sqrt(2*np.pi))\n",
    "    num = -1*np.power((x-mu),2)\n",
    "    denom = (2*sigma*sigma)\n",
    "    return coeff * np.exp(num/denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part C - Part 1\n",
    "# Record p(Xj | w0) and p(Xj | w1) into vals_0 and vals_1 respectively\n",
    "# We simply record the full array here, leaving it expanded to the features\n",
    "\n",
    "vals_1 = list()\n",
    "vals_0 = list()\n",
    "\n",
    "for row in range(len(X_test)):\n",
    "    for feature in range(len(X_test[row])):\n",
    "        new_val = []\n",
    "        new_val.append(normpdf(X_test[row][feature], columnMeans_1[feature], columnSTD_1[feature]))\n",
    "        vals_1.append(new_val)\n",
    "        \n",
    "    for feature in range(len(X_test[row])):\n",
    "        new_val = []\n",
    "        new_val.append(normpdf(X_test[row][feature], columnMeans_0[feature], columnSTD_0[feature]))\n",
    "        vals_0.append(new_val)\n",
    "        \n",
    "vals_1 = np.array(vals_1, dtype='f')\n",
    "vals_0 = np.array(vals_0, dtype='f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part C - Part 2\n",
    "# Multiply the 8 values of each row together\n",
    "\n",
    "for i, row in enumerate(vals_1):\n",
    "    vals_1[i] = np.prod(row)\n",
    "    \n",
    "for i, row in enumerate(vals_0):\n",
    "    vals_0[i] = np.prod(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly classified: 0.6491228070175439%\n"
     ]
    }
   ],
   "source": [
    "# Rest of Part C\n",
    "\n",
    "posterior_1 = 0.35 * vals_1\n",
    "posterior_0 = 0.65 * vals_0\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(Y_test)):\n",
    "    positive_case = posterior_1[i] > posterior_0[i]\n",
    "    if positive_case == Y_test[i]: correct += 1\n",
    "\n",
    "print(\"Correctly classified: \" + str(correct/len(Y_test)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "\n",
    "### Source: https://www.machinelearningplus.com/statistics/mahalanobis-distance/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create covariance and inverse covariance matrix - plot using matplotlib import\n",
    "\n",
    "cov = np.cov(X_train.T)\n",
    "plt.matshow(cov)\n",
    "plt.show()\n",
    "inv_cov = np.linalg.inv(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.26       109.777145    67.90857     19.53143     67.69143\n",
      "  29.939716     0.44142282  31.385714  ]\n",
      "[  4.8210526 139.6421     69.68421    21.847368  100.82632    35.26\n",
      "   0.5659263  36.33684  ]\n"
     ]
    }
   ],
   "source": [
    "# Means and std for class 0 and 1\n",
    "mean_0 = np.array(columnMeans_0)\n",
    "mean_1 = np.array(columnMeans_1)\n",
    "\n",
    "print(mean_0)\n",
    "print(mean_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(X_test)\n",
    "\n",
    "# Find M distance for negative cases\n",
    "step1 = np.dot((data - mean_0), inv_cov)\n",
    "step2 = np.dot(step1, (data-mean_0).T)\n",
    "d_0 = step2.diagonal()\n",
    "\n",
    "\n",
    "# Find M distance for positive cases\n",
    "step1 = np.dot((data - mean_1), inv_cov)\n",
    "step2 = np.dot(step1, (data-mean_1).T)\n",
    "d_1 = step2.diagonal()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprime_0 = d_0 - np.log(0.65)\n",
    "dprime_1 = d_1 - np.log(0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly classified: 0.7982456140350878%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(Y_test)):\n",
    "    positive_case = dprime_1[i] < dprime_0[i]\n",
    "    if positive_case == Y_test[i]:\n",
    "        correct += 1\n",
    "print(\"Correctly classified: \" + str(correct/len(Y_test)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Between Classifiers\n",
    "\n",
    "You do this i dont wanna :^("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
